{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17nS-yA_hsFND4ctVXF7EUaBQuhTioQa3",
      "authorship_tag": "ABX9TyM1ab4hANjUV2PubxozjaOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GKouv89/tt8/blob/tempNavigation/dataScripts/excelToCSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L2LSCLhVV_Z"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/TT8/Sociodrama 1/All data - superepisodes\"\n",
        "target_path = \"/content/drive/MyDrive/TT8/CSV files\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fnmatch\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ShNLXpQDUpFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read first file\n",
        "file_list = os.listdir(path)"
      ],
      "metadata": {
        "id": "vdpWGkb6WrSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = path + '/' + file_list[0]\n",
        "file_name_no_ending = file_list[0].replace('.xlsx', '')\n",
        "new_file_path = target_path + '/' + file_name_no_ending + '.csv'\n",
        "myfile = pd.read_excel(file_path)\n",
        "myfile.to_csv(new_file_path, index = None, header=True)"
      ],
      "metadata": {
        "id": "OBvpxJLGX378"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, make folders for all scenes\n",
        "# Then, move data from all data folder, to respective scene folders, with correct format\n",
        "# First, find scene number. Following naming convention, its the number right after the Scene word\n",
        "def findSceneNo(name, from_file=True):\n",
        "  scene_no = name.split(\"Scene\")\n",
        "  if from_file:\n",
        "    # But the scene number could be 1, 2 or 3 digits long. So let's remove the part that's after the biometric\n",
        "    # Which biometric is it? So far, 3 choices. \n",
        "    temp = scene_no[1].find(\"HR\")\n",
        "    if(temp == -1):\n",
        "      temp = scene_no[1].find(\"SC\")\n",
        "      if(temp == -1):\n",
        "        return scene_no[1].split(\"Temp\")[0]\n",
        "      else:\n",
        "        return scene_no[1].split(\"SC\")[0]\n",
        "    else:\n",
        "      return scene_no[1].split(\"HR\")[0]\n",
        "  else:\n",
        "    return scene_no[1]"
      ],
      "metadata": {
        "id": "v76PHerbaJcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store a list of all the lists that we have created folders for\n",
        "scenesList = []"
      ],
      "metadata": {
        "id": "SyiWXz3WeZo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertToCSV(file_list):\n",
        "  for file_name in file_list:\n",
        "    scene_no = findSceneNo(file_name)\n",
        "    folder_name = \"Scene\" + scene_no\n",
        "    folder = os.path.join(target_path, folder_name)\n",
        "    if int(scene_no) not in scenesList:\n",
        "      scenesList.append(int(scene_no))\n",
        "      os.mkdir(folder)\n",
        "    # Create file\n",
        "    myfile = pd.read_excel(os.path.join(path, file_name))\n",
        "    file_name_new = file_name.replace('.xlsx', '') + '.csv'\n",
        "    myfile.to_csv(os.path.join(folder, file_name_new), index = None, header=True)"
      ],
      "metadata": {
        "id": "elmMijyhe24n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convertToCSV(file_list)"
      ],
      "metadata": {
        "id": "LjkLUseXZb-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findSection(file):\n",
        "  print(\"File: \", file)\n",
        "  first_occ = file.find(\"Introduction\")\n",
        "  if first_occ == -1:\n",
        "    first_occ = file.find(\"Section\")\n",
        "    if first_occ == -1:\n",
        "      return \"Conclusion\"\n",
        "    else:\n",
        "      # Find section number, too\n",
        "      return file.split(\"Section\")[1].split(\".\")[0]\n",
        "  else:\n",
        "    return \"Introduction\"\n",
        "\n",
        "\n",
        "def concatDiffSectionsBiometric(file_list, biometric, scene_dir, scene_no):\n",
        "  # First, find all files in the list that have a specific biometric\n",
        "  sensor_files = fnmatch.filter(file_list, \"*{}*\".format(biometric))\n",
        "  print(\"Biometric: {}, sensor files: {}\".format(biometric, sensor_files))\n",
        "  # Types of section names could be something like \n",
        "  # Introduction\n",
        "  # Section X-Y\n",
        "  # Conclusion\n",
        "  # These files should be two. Find out the section.\n",
        "  if len(sensor_files) == 2:\n",
        "    sections = []\n",
        "    sections.append(findSection(sensor_files[0]))\n",
        "    sections.append(findSection(sensor_files[1]))\n",
        "    print(\"Sections for scene {} are {} and {}\".format(scene_no, sections[0], sections[1]))\n",
        "    # Compare sections. Do we have a conclusion or intro? things become easier\n",
        "    if \"Introduction\" in sections:\n",
        "      first_section = sections.index(\"Introduction\")\n",
        "      [second_section] = [ind for ind, x in enumerate(sections) if ind != first_section]\n",
        "      print(\"Section {} comes before section {}.\".format(sections[first_section], sections[second_section]))\n",
        "    elif \"Conclusion\" in sections:      \n",
        "      second_section = sections.index(\"Conclusion\")\n",
        "      [first_section] = [ind for ind, x in enumerate(sections) if ind != second_section]\n",
        "      print(\"Section {} comes before section {}.\".format(sections[first_section], sections[second_section]))\n",
        "    else:\n",
        "      print(\"Both sections are middle sections\")\n",
        "      # Both sections X1-Y1 and X2-Y2, we must compare\n",
        "      section_a = int(sections[0].split(\"-\")[0])\n",
        "      section_b = int(sections[1].split(\"-\")[0])\n",
        "      if section_a != section_b:\n",
        "        first_section = 0 if section_a < section_b else 1\n",
        "        [second_section] = [ind for ind, x in enumerate(sections) if ind != first_section]\n",
        "        print(\"Section {} comes before section {}.\".format(sections[first_section], sections[second_section]))\n",
        "      else:\n",
        "        # Same section, different subsections. Compare\n",
        "        subsection_a = int(sections[0].split(\"-\")[1])\n",
        "        subsection_b = int(sections[1].split(\"-\")[1])\n",
        "        print(subsection_a)\n",
        "        print(subsection_b)\n",
        "        if subsection_a != subsection_b:\n",
        "          print(\"blah\")\n",
        "          first_section = 0 if subsection_a < subsection_b else 1\n",
        "          [second_section] = [ind for ind, x in enumerate(sections) if ind != first_section]\n",
        "          print(\"Section {} comes before section {}.\".format(sections[first_section], sections[second_section]))\n",
        "        else:\n",
        "          print(\"ERROR. FILES: \", sensor_files)\n",
        "    # Now that we know which section is first and which is second, we concatenate the file to a larger one.\n",
        "    first_file = pd.read_csv(os.path.join(scene_dir, sensor_files[first_section]), header=None)\n",
        "    second_file = pd.read_csv(os.path.join(scene_dir, sensor_files[second_section]), header=None)\n",
        "    temp_frame = pd.concat([first_file, second_file], ignore_index=True)\n",
        "    return temp_frame\n",
        "  else:\n",
        "    print(\"Error. Files: \", sensor_files)\n",
        "\n",
        "\n",
        "def concatDiffSections(file_list, scene_dir, scene_no, sensor_name):\n",
        "  new_file_list = []\n",
        "  for biometric in [\"HR\", \"SC\", \"Temp\"]:\n",
        "    new_file_list.append(concatDiffSectionsBiometric(file_list, biometric, scene_dir, sensor_name))\n",
        "  return new_file_list"
      ],
      "metadata": {
        "id": "QOnSy-3mgoVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def performConcatenation(files, scene_no, sensor_name, scene_dir):\n",
        "  temp_frame = pd.concat(files, axis=1)\n",
        "  concat_file_name = \"Scene{}All{}.csv\".format(scene_no, sensor_name)\n",
        "  # print(concat_file_name)\n",
        "  temp_path = os.path.join(dir_path, concat_file_name)\n",
        "  temp_frame.to_csv(temp_path, index=False, header=['HR', 'SC', 'Temp'])\n",
        "  # Reread file to add header and re-export\n",
        "  # temp_frame = pd.read_csv(temp_path, names=['HR', 'SC', 'Temp'])\n",
        "  # temp_frame.to_csv(temp_path, index=False)\n",
        "\n",
        "def concatCSV(file_list, sensor_name, scene_dir):\n",
        "  files = []\n",
        "  scene_no = findSceneNo(scene_dir, from_file=False)\n",
        "  file_list.sort()\n",
        "  # print(file_list)\n",
        "  # This is useful to avoid certain scenes that belong to two sessions\n",
        "  if len(file_list) > 3:\n",
        "    print(\"Scene {} is split between sections.\".format(scene_no))\n",
        "    files = concatDiffSections(file_list, scene_dir, scene_no, sensor_name)\n",
        "    performConcatenation(files, scene_no, sensor_name, scene_dir)\n",
        "  elif len(file_list) == 3:\n",
        "    print('hi1')\n",
        "    for ff in file_list:\n",
        "      print('ff: {}'.format(ff))\n",
        "      files.append(pd.read_csv(os.path.join(scene_dir, ff), header=None))\n",
        "    performConcatenation(files, scene_no, sensor_name, scene_dir)"
      ],
      "metadata": {
        "id": "vFfSZ0kMwod7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all files that have to do with a specific sensor for a specific scene\n",
        "dir_list = fnmatch.filter(os.listdir(target_path), \"Scene*\")\n",
        "for dir in dir_list:\n",
        "  for i in range(1, 7):\n",
        "    sensor_name = \"Sensor\" + str(i)\n",
        "    dir_path = os.path.join(target_path, dir)\n",
        "    if os.path.isdir(dir_path):\n",
        "      file_list_min = fnmatch.filter(os.listdir(dir_path), \"*{}*\".format(sensor_name))\n",
        "      file_list_already_done = fnmatch.filter(file_list_min, \"*All*\")\n",
        "      file_list_min = [x for x in file_list_min if x not in file_list_already_done]\n",
        "      concatCSV(file_list_min, sensor_name, dir_path)"
      ],
      "metadata": {
        "id": "6TIeHOYir9p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete initial csvs and keep only \"All\"\n",
        "from os import walk\n",
        "for (root, dirs, all_files) in walk(target_path):\n",
        "  all_files_min = fnmatch.filter(all_files, \"*All*\")\n",
        "  all_files_diff = [x for x in all_files if x not in all_files_min]\n",
        "  for name in all_files_diff:\n",
        "    # print(os.path.join(root, name))\n",
        "    os.remove(os.path.join(root, name))\n",
        "\n",
        "for (root, dirs, all_files) in walk(target_path):\n",
        "  for name in all_files:\n",
        "    print(os.path.join(root,name))\n",
        "  print(\"*************\")"
      ],
      "metadata": {
        "id": "p9OTZwMcA4Nb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}